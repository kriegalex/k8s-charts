# {{ .Name }}

{{ template "chart.versionBadge" . }}{{ template "chart.typeBadge" . }}{{ template "chart.appVersionBadge" . }}

{{ template "chart.description" . }}

## Introduction

This Helm chart deploys a [strfry](https://github.com/hoytech/strfry) Nostr relay on a Kubernetes cluster. Strfry is a high-performance, resource-efficient Nostr relay implementation written in C++, designed to handle high traffic loads while maintaining efficient resource usage.

## Prerequisites

- Kubernetes 1.12+
- Helm 3.0+
- PV provisioner support in the underlying infrastructure (if persistence is enabled)

## Installing the Chart

To install the chart with the release name `my-relay`:

```bash
helm install my-relay ./nostr-strfry
```

## Uninstalling the Chart

To uninstall/delete the `my-relay` deployment:

```bash
helm delete my-relay
```

## Configuration

The following table lists the configurable parameters for the nostr-strfry chart and their default values.

{{ template "chart.valuesTable" . }}

## Persistence

This chart mounts a Persistent Volume for the strfry database. The volume is created using dynamic volume provisioning. If you want to disable this (and instead use an emptyDir volume), set `persistence.enabled` to `false`.

For production use, it's recommended to:
- Use a reliable storage class
- Set an appropriate volume size (default is 10Gi)
- Consider backup strategies for your database

## Ingress and Reverse Proxy

This chart includes support for Ingress resources. If you have an Ingress controller installed on your cluster, such as [nginx-ingress](https://kubernetes.github.io/ingress-nginx/) or [traefik](https://traefik.io/), you can utilize the ingress controller to serve your Nostr relay.

For proper WebSocket support in an ingress configuration, you may need to add specific annotations. For example, with NGINX:

```yaml
ingress:
  enabled: true
  annotations:
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-body-size: "64m"
  hosts:
    - host: relay.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: relay-tls
      hosts:
        - relay.example.com
```

## NIP Support

Strfry supports multiple NIPs (Nostr Implementation Possibilities). You can specify the supported NIPs in your values file:

```yaml
config:
  relay:
    info:
      nips: "[1, 2, 4, 9, 11, 22, 28, 40, 70, 77]"
```

## Using with Kubernetes

Once your relay is deployed, you can access it using the service endpoint. The default configuration creates a ClusterIP service, which means it's only accessible within the cluster.

### Accessing the Relay

1. For internal cluster access:
   ```
   ws://RELEASE-NAME-nostr-strfry.NAMESPACE.svc.cluster.local:7777
   ```

2. To access from your local machine:
   ```bash
   kubectl port-forward --namespace NAMESPACE svc/RELEASE-NAME-nostr-strfry 7777:7777
   ```
   Then connect to `ws://localhost:7777`

3. If you enabled Ingress, use the domain you specified.

### Checking Logs

To view the logs of your relay:
```bash
kubectl logs -f deployment/RELEASE-NAME-nostr-strfry -n NAMESPACE
```

## Notes on Production Use

For production deployments, consider:

1. Using a specific image tag rather than `latest`
2. Setting appropriate resource limits and requests
3. Enabling TLS via Ingress or another method
4. Setting up proper monitoring and backup strategies for the database
5. Configuring appropriate parameters for your expected load:
   - `maxWebsocketPayloadSize`
   - `maxFilterLimit`
   - `maxSubsPerConnection`
   - Thread counts based on your server capacity
6. Setting up a proper NIP-11 info section with your relay information
7. Enabling and configuring the Negentropy protocol for efficient relay synchronization

{{ template "helm-docs.versionFooter" . }}
